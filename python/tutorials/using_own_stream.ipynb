{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f7091f",
   "metadata": {},
   "source": [
    "# 02. Using a custom stream\n",
    "This tutorial shows how to use segyio with your own I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## azure-storage-blob and smart_open libraries are needed only if you wish run azure examples.\n",
    "%pip install dotenv pytest smart_open[azure] azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a71058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pytest\n",
    "\n",
    "import segyio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a72557",
   "metadata": {},
   "source": [
    "## Using simple stream\n",
    "Users can run segyio with any file-like object I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = open(\"viking_small.segy\", \"rb\")\n",
    "with segyio.open_with(stream=stream, ignore_geometry=True) as f:\n",
    "    print(f'trace count: {f.tracecount}')\n",
    "\n",
    "# >>> trace count: 480"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745463f",
   "metadata": {},
   "source": [
    "Such I/O freedom comes with the cost:\n",
    "- First of all, it would always be slower than working with local files through `segyio.open()`.\n",
    "- Secondly, applying custom sources might be incompatible with segyio in unpredictable ways (dev team would provide very limited assistance with those).\n",
    "\n",
    "Next part of the tutorial shows some problems users might encounter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b742ce2",
   "metadata": {},
   "source": [
    "## Example of cloud I/O\n",
    "\n",
    "This part of tutorial uses Azure cloud and `smart_open` library, but its logic can be tailored to other I/Os.\n",
    "\n",
    "To run the code below you need to \n",
    " 1) have `python/test-data/tiny.sgy` available in your Azure Blob Storage\n",
    " 2) define `AZURE_ACCOUNT_NAME` (e.g. myaccount), `AZURE_BLOB_PATH` (e.g. container/tiny.sgy) and `AZURE_SAS_TOKEN` (with read/write permissions to tiny.sgy) environment variables in `.env` file.\n",
    "\n",
    "💰 **Warning**: be aware of your cloud pricing model, as segyio would send to I/O as many requests as it would to a local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def open_azure(uri: str, mode: str):\n",
    "    if not mode.endswith('b'):\n",
    "        mode += 'b'\n",
    "    account_name = os.environ['AZURE_ACCOUNT_NAME']\n",
    "    sas_token = os.environ['AZURE_SAS_TOKEN']\n",
    "    account_url = f\"https://{account_name}.blob.core.windows.net/?{sas_token}\"\n",
    "    transport_params = {\n",
    "        'client': BlobServiceClient(account_url=account_url),\n",
    "    }\n",
    "    return smart_open.open(uri, mode, transport_params=transport_params)\n",
    "\n",
    "\n",
    "blob = os.environ['AZURE_BLOB_PATH']\n",
    "uri = f'azure://{blob}'\n",
    "with segyio.open_with(stream=open_azure(uri, \"rb\")) as f:\n",
    "    print(f'trace count: {f.tracecount}')\n",
    "\n",
    "# >>> trace count: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab96291",
   "metadata": {},
   "source": [
    "## Testing\n",
    " \n",
    "You can optionally try running some of the existing segyio tests on your own I/O to discover what should work and what definitely does not. For this you need to\n",
    "1) have segyio tests source code available.\n",
    "2) have `python/test-data/tiny.sgy` file present in your I/O system.\n",
    "\n",
    "⚠️ **Note**: this information is presented only for convenience and is not an official part of segyio. There is no guarantee that testing framework won't be changed in the future without any notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4938858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the tests and find out which operations are supported and how well they are supported,\n",
    "# you need to run stream.py tests, pass \"--custom_stream\" marker and specify a plugin which knows how to make your stream.\n",
    "def run_pytest(plugin):\n",
    "   pytest.main([\"--custom_stream\", \"--durations=5\", \"../test/stream.py\"], plugins=[plugin])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520b45c",
   "metadata": {},
   "source": [
    "### Running tests on local file\n",
    "Note that running `segyio.open_with` on a local file obtained through Python's own `open(filename)` is slower than running `segyio.open(filename)` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your plugin class which implements 'make_stream' fixture.\n",
    "# Testing framework will call 'make_stream(path, mode)'.\n",
    "#\n",
    "# Note that some tests will make a call several times to the same path. It is up\n",
    "# to the user to assure that call to the same path returns the same data (think:\n",
    "# creating or updating a file and then opening it again for reading).\n",
    "\n",
    "class PyFilePlugin:\n",
    "    @pytest.fixture(scope=\"function\")\n",
    "    def make_stream(self, tmp_path_factory):\n",
    "        filepaths = {}\n",
    "\n",
    "        def _make_stream(path, mode):\n",
    "            filename = os.path.basename(path)\n",
    "            if filename in filepaths:\n",
    "                return open(filepaths[filename], mode)\n",
    "\n",
    "            path_r = \"../../test-data/\" + filename\n",
    "            path_w = tmp_path_factory.getbasetemp() / filename\n",
    "            if mode == \"rb\":\n",
    "                path = path_r\n",
    "            elif mode == \"w+b\":\n",
    "                path = path_w\n",
    "            elif mode == \"r+b\":\n",
    "                shutil.copy(path_r, path_w)\n",
    "                path = path_w\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported mode {mode}\")\n",
    "\n",
    "            filepaths.update({filename: path})\n",
    "            return open(path, mode)\n",
    "        yield _make_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2642163",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pytest(PyFilePlugin())\n",
    "# >>> [all expected tests passed]\n",
    "# >>> ============================= slowest 5 durations ==============================\n",
    "# >>> 0.01s call     test/stream.py::test_update\n",
    "# >>> 0.01s call     test/stream.py::test_create\n",
    "# >>> 0.01s teardown test/stream.py::test_reopen_closed\n",
    "# >>> 0.01s call     test/stream.py::test_read[True]\n",
    "# >>> \n",
    "# >>> (1 durations < 0.005s hidden.  Use -vv to show these durations.)\n",
    "# >>> ========================= 9 passed, 3 xfailed in 0.32s ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b5d1e",
   "metadata": {},
   "source": [
    "### Running tests on cloud\n",
    "\n",
    "Be aware that running tests on cloud can be slow as many requests are sent over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureDatasourcePlugin:\n",
    "    def __init__(self, open_stream=open_azure):\n",
    "        self.open_stream = open_stream\n",
    "\n",
    "    @pytest.fixture(scope=\"function\")\n",
    "    def make_stream(self):\n",
    "        uris = {}\n",
    "\n",
    "        def _make_stream(path, mode):\n",
    "            if path in uris:\n",
    "                return self.open_stream(uris[path], mode)\n",
    "            \n",
    "            blob = os.environ['AZURE_BLOB_PATH']\n",
    "            \n",
    "            # note that used library doesn't actually support r+ and w+ modes,\n",
    "            # but uri must be valid \n",
    "            if mode == \"rb\":\n",
    "                uri = f'azure://{blob}'\n",
    "            elif mode == \"w+b\":\n",
    "                # hardcoded for simplicity\n",
    "                uri = f'azure://test/new.sgy'\n",
    "            elif mode == \"r+b\":\n",
    "                # data could be copied to different blob to avoid overwriting,\n",
    "                # but overwriting here for simplicity\n",
    "                uri = f'azure://{blob}'\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported mode {mode}\")\n",
    "\n",
    "            uris.update({path: uri})\n",
    "            return self.open_stream(uri, mode)\n",
    "        yield _make_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pytest(AzureDatasourcePlugin())\n",
    "# >>> ============================================================================================= slowest 5 durations =============================================================================================\n",
    "# >>> 9.71s call     test/stream.py::test_read[False]\n",
    "# >>> 9.26s call     test/stream.py::test_read[True]\n",
    "# >>> 1.97s call     test/stream.py::test_reopen_closed\n",
    "# >>> 1.20s call     test/stream.py::test_read_cube\n",
    "# >>> 1.10s call     test/stream.py::test_resource_deallocation[2]\n",
    "# >>> =========================================================================================== short test summary info ===========================================================================================\n",
    "# >>> FAILED ../test/stream.py::test_create - NotImplementedError: Azure Blob Storage support for mode 'wb+' not implemented\n",
    "# >>> FAILED ../test/stream.py::test_update - NotImplementedError: Azure Blob Storage support for mode 'rb+' not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef084bf1",
   "metadata": {},
   "source": [
    "We can see that `test_create` and `test_update` failed as functionality is not supported by this I/O. That informs us that this I/O is compatible only with segyio read functionality.\n",
    "\n",
    "We also see that reading is very slow compared to local file, which is to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed111c",
   "metadata": {},
   "source": [
    "\n",
    "## Custom file-like objects\n",
    "\n",
    "Sometimes it is desirable to implement own version of file-like object.\n",
    "\n",
    "⚠️ **Note**: from segyio perspective implementing `read`/`write`/`seek`/`tell`/`flush`/`close`/`writable` methods with correct [signatures](https://github.com/python/cpython/blob/main/Lib/_pyio.py) should be a good starting point, but we do not guarantee that required functions won't be changed.\n",
    "\n",
    "Instead of implementing brand new file-like object, lets just tweak `read` method of our Azure object to speed things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumb, untested and buggy speedup, demo purpose only:\n",
    "# cache last read chunk of data and use it if next request hits it\n",
    "class AzureSpeedupIO():\n",
    "    def __init__(self, azure_smart_open):\n",
    "        self.azure = azure_smart_open\n",
    "        self.cache = b''\n",
    "        self.cache_tell = 0\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.azure, name)\n",
    "\n",
    "    def read(self, size):\n",
    "        current_tell = self.azure.tell()\n",
    "        offset = current_tell - self.cache_tell\n",
    "\n",
    "        if offset < 0 or len(self.cache) - offset < size:\n",
    "            greedy_read_size = 1024\n",
    "            requested = max(size, greedy_read_size)\n",
    "            self.cache = self.azure.read(requested)\n",
    "            self.cache_tell = current_tell\n",
    "            offset = 0\n",
    "        else:\n",
    "            # read must change tell position. ignore seek > EOF compatibility\n",
    "            self.azure.seek(size, 1)\n",
    "\n",
    "        return self.cache[offset:offset + size]\n",
    "\n",
    "\n",
    "def open_stream_speedup(filename, mode):\n",
    "    return AzureSpeedupIO(open_azure(filename, mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pytest(AzureDatasourcePlugin(open_stream=open_stream_speedup))\n",
    "# >>> ============================================================================================= slowest 5 durations =============================================================================================\n",
    "# >>> 3.29s call     test/stream.py::test_read[False]\n",
    "# >>> 3.25s call     test/stream.py::test_read[True]\n",
    "# >>> 0.90s call     test/stream.py::test_reopen_closed\n",
    "# >>> 0.52s call     test/stream.py::test_read_cube\n",
    "# >>> 0.47s call     test/stream.py::test_not_closing_does_not_cause_segfault"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe01103",
   "metadata": {},
   "source": [
    "💡 **Note**: we see that tests became significantly faster, which shows how I/O implementation affects segyio performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py13venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
